{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4469026-5a1f-489e-9563-21e5420168f5",
   "metadata": {},
   "source": [
    "# MHWs statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8931d7-8e04-4469-acaa-ca5ca08d5227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('/home/b/b382616/notebooks_home/MHW/ocetrac-dask')\n",
    "import ocetrac_dask\n",
    "import os\n",
    "import imageio\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.dates as mdates\n",
    "import intake\n",
    "import dask\n",
    "\n",
    "# Visualization packages\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from matplotlib.animation import FFMpegWriter\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "\n",
    "from tempfile import TemporaryDirectory\n",
    "from getpass import getuser\n",
    "from pathlib import Path\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "\n",
    "\n",
    "import itertools\n",
    "import gc\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf634f99-0aad-4c94-b9d3-d87ea8a28fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(n_workers=32, threads_per_worker=4)\n",
    "client = Client(cluster)\n",
    "client\n",
    "\n",
    "# My dashboard hack\n",
    "remote_node = subprocess.run(['hostname'], capture_output=True, text=True).stdout.strip().split('.')[0]\n",
    "port = re.search(r':(\\d+)/', client.dashboard_link).group(1)\n",
    "print(f\"Forward with Port = {remote_node}:{port}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db3c22a9-2cfd-412b-b469-82e2f495511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch_dir = Path('/scratch') / 'b' / 'b382616' / 'mhws' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12f2deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = {'time': 100, 'lat': -1, 'lon': -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdec834-4a3c-4308-93c5-e8535b560538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load just the Data Array, and immediately convert to int32\n",
    "mhw_labels = xr.open_zarr(str(scratch_dir / '02_track_dask_newmaskk.zarr'), chunks=chunk_size).labels.astype(np.int32)\n",
    "mhw_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecd77f9-cffa-4844-98e6-a51c4590eef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't use unique !\n",
    "\n",
    "# Make a Data Array so that we can expand out the dimension 'event'\n",
    "event_ids = xr.DataArray(np.arange(0,mhw_labels.max().compute().values+1, dtype=np.int32), dims='event').chunk({'event': 1000})\n",
    "event_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e0d0a4-b28b-4d80-88f8-ce13e9c9f4ff",
   "metadata": {},
   "source": [
    "# Formation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6708fe-c702-491b-85b5-8517637c4548",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Option 1: This will work because we reduce the 3D matrix ASAP\n",
    "#    Still not great because we have an inefficient loop and store data in a communal list --> Not parallel\n",
    "\n",
    "formation_events=[]\n",
    "for i in event_ids:\n",
    "    binary_event = (mhw_labels == i).sum(dim={'lat','lon'})  # False when not occurring in that time, True if event present at that time\n",
    "    start_index = binary_event.argmax().compute().values\n",
    "    formation_events.append(mhw_labels.isel(time=start_index))\n",
    "\n",
    "combined_formation = xr.concat(formation_events, dim='event')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12772173-7dc4-4147-bbce-585efe9c65e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Option 2/Better:  \n",
    "#   Avoid the for loop && keep it lazy\n",
    "#   Don't force all the event slices to be in the same memory\n",
    "#   Use binary type which is 64x smaller than float... Means it's going to be ~64x faster \n",
    "#   All this allows chunking still in lat/lon/time ðŸ‘Œ\n",
    "# .... Requires many chunks because we expand binary_events to a 4D array ðŸ˜©\n",
    "\n",
    "# * This will do all events at the same time, but keeping it lazy\n",
    "binary_events = (mhw_labels == event_ids).any(dim={'lat','lon'})   # Dimension is now (time x event)\n",
    "start_indexes = binary_events.argmax(dim='time').compute().values\n",
    "\n",
    "# Make another Data Array so that we'll keep event when we extract time\n",
    "start_indexes_da = xr.DataArray(start_indexes, dims='event', coords={'event': event_ids})\n",
    "\n",
    "# Extract the time slice for each event\n",
    "formation_events = (mhw_labels == event_ids).isel(time=start_indexes_da)\n",
    "\n",
    "# NB: this is still lazy // not computed yet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1c08546",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "## Option 3/Best:\n",
    "#  Avoid even having to make the binary_events array and 4D dimension expansion\n",
    "\n",
    "# * This will do all events at the same time, but keeping it lazy\n",
    "def clever_binary_events(mhw_labels_chunk, max_ids):\n",
    "    unique_labels = np.unique(mhw_labels_chunk[mhw_labels_chunk>=0])\n",
    "    binary_events_chunk = np.zeros(max_ids, dtype=bool)\n",
    "    binary_events_chunk[unique_labels] = True\n",
    "    return binary_events_chunk\n",
    "\n",
    "binary_events = xr.apply_ufunc(\n",
    "            clever_binary_events,\n",
    "            mhw_labels,\n",
    "            event_ids.shape[0],\n",
    "            input_core_dims=[['lat','lon'],[]],\n",
    "            output_core_dims=[['event']],\n",
    "            vectorize=True,\n",
    "            dask='parallelized',\n",
    "            output_sizes={'event': event_ids.shape[0]},\n",
    "            output_dtypes=[bool]\n",
    "        )\n",
    "\n",
    "start_indexes = binary_events.argmax(dim='time').compute().values\n",
    "\n",
    "# Make another Data Array so that we'll keep event when we extract time\n",
    "start_indexes_da = xr.DataArray(start_indexes, dims='event', coords={'event': event_ids})\n",
    "\n",
    "# Extract the time slice for each event\n",
    "formation_events = xr.apply_ufunc(\n",
    "            lambda x, y: x == y,\n",
    "            mhw_labels.isel(time=start_indexes_da), # This has dimension (event, lat, lon)\n",
    "            event_ids,\n",
    "            input_core_dims=[['lat','lon'],[]],\n",
    "            output_core_dims=[['lat', 'lon']],\n",
    "            vectorize=True,\n",
    "            dask='parallelized',\n",
    "            output_dtypes=[bool]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78971da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formation heat map\n",
    "formation_heatmap = formation_events.sum(dim='event')\n",
    "\n",
    "formation_heatmap.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
